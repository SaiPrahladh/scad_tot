{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from clustering import LGKUtils\n",
    "from robustness import verify_regions, save_verified_regions\n",
    "\n",
    "class MockLGKCluster:\n",
    "    def __init__(self, regions, categories):\n",
    "        self.__regions = regions\n",
    "        self.__categories = categories\n",
    "    \n",
    "    def get_regions(self, sort=True):\n",
    "        return sorted(self.__regions, key=lambda r:(r.n, r.density), reverse=True)\n",
    "    \n",
    "    def get_categories(self):\n",
    "        return self.__categories\n",
    "\n",
    "def verify_subset_regions(startidx, endidx, save=True):\n",
    "    lgkc = LGKUtils.load('../artifacts/test/lgkm.pkl')\n",
    "    regions, categories = lgkc.get_regions(sort=True)[startidx:endidx], lgkc.get_categories()\n",
    "    mock_lgkc = MockLGKCluster(regions, categories)\n",
    "    nnet_path = '../network/models/latest/model.nnet'\n",
    "    vregions = verify_regions(nnet_path, mock_lgkc, nmin=2, eprec=0.0001, rpad=10, verbose=1)\n",
    "    if save: save_verified_regions(vregions, outdir=f'../artifacts/test/vr_{startidx}_{endidx-1}')\n",
    "    return vregions\n",
    "\n",
    "results = []\n",
    "for i in range(5, 10):\n",
    "    start, end = i*100, (i+1)*100\n",
    "    print(f'verifying regions {start}-{end-1}')\n",
    "    results.extend(verify_subset_regions(start, end))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from clustering import LGKUtils\n",
    "\n",
    "n_outputs = 5\n",
    "verification_csv = '../data/latest/verification.csv'\n",
    "X_orig, y_orig = LGKUtils.load_dataset(verification_csv, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_orig.shape, y_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def remove_outliers(X, y, tolerance):\n",
    "    idxs = np.where((np.abs(stats.zscore(X)) < tolerance).all(axis=1))[0]\n",
    "    return X[idxs], y[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from clustering import LGKClustering, LGKUtils\n",
    "\n",
    "X, y = X_orig.copy(), y_orig.copy()\n",
    "X, y = remove_outliers(X, y, 10)\n",
    "lgkmc = LGKClustering().fit(X, y, init_centroid='rand') # rand, first, none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LGKUtils.save(lgkmc, outdir='../artifacts/test')dss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LGKUtils.print_regions(lgkmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('n == 1: %d' % sum([1 for r in lgkmc.get_regions() if r.n == 1]))\n",
    "print('n > 1: %d' % sum([1 for r in lgkmc.get_regions() if r.n > 1]))\n",
    "print('n >= 10: %d' % sum([1 for r in lgkmc.get_regions() if r.n >= 10]))\n",
    "print('n >= 100: %d' % sum([1 for r in lgkmc.get_regions() if r.n >= 100]))\n",
    "print('n >= 1000: %d' % sum([1 for r in lgkmc.get_regions() if r.n >= 1000]))\n",
    "print('n >= 10000: %d' % sum([1 for r in lgkmc.get_regions() if r.n >= 10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r0 = lgkmc.get_regions(sort=True)[0]\n",
    "r0.n, r0.radius, r0.density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r0.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from clustering import LGKUtils\n",
    "# from robustness import verify_region\n",
    "# from tot_net import TOTNet\n",
    "\n",
    "# net = TOTNet('../network/models/latest/model.nnet')\n",
    "# lgkc = LGKUtils.load('../artifacts/test/lgkm.pkl')\n",
    "# r, ncategories, eprec = lgkc.get_regions(sort=True)[0], len(lgkc.get_categories()), 0.0001\n",
    "# vr = verify_region(net, r, ncategories, eprec, rpad=1, verbose=1)\n",
    "# vr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from clustering import LGKUtils, LGKClustering\n",
    "from robustness import verify_regions, save_verified_regions\n",
    "\n",
    "nnet_path = '../network/models/latest/model.nnet'\n",
    "lgkc = LGKUtils.load('../artifacts/test/lgkm.pkl')\n",
    "vregions = verify_regions(nnet_path, lgkc, nmin=10, eprec=0.0001, rpad=10, verbose=1)\n",
    "vregions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_verified_regions(vregions, outdir='../artifacts/vregions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import TOTUtils, tohex\n",
    "\n",
    "lgkmc = LGKMeansUtils.load('../artifacts/lgkm.pkl')\n",
    "regions = lgkmc.get_regions(sort=False)\n",
    "viz_X = [x for r in regions for x in r.X] + [r.centroid for r in regions]\n",
    "viz_y = [y for r in regions for y in r.y] + [n_outputs+r.category for r in regions]\n",
    "\n",
    "features, categories = TOTUtils.get_feature_names(), TOTUtils.get_category_names()\n",
    "viz_df = pd.DataFrame(viz_X, columns=features)\n",
    "viz_df['y'] = viz_y\n",
    "\n",
    "colors = [tohex(r,g,b) for r,g,b in sns.color_palette('rainbow_r', n_outputs)]\n",
    "palette = {i:colors[i if i < n_outputs else i-n_outputs] for i in range(n_outputs*2)}\n",
    "markers = ['o' if i < n_outputs else 'D' for i in range(n_outputs*2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(viz_df, hue='y', corner=True, palette=palette, markers=markers, plot_kws=dict(alpha=0.5, s=10))\n",
    "g = g.add_legend()\n",
    "g.savefig('../artifacts/lgkmtest.png', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.PairGrid(viz_df, hue='y', vars=features, palette=palette, hue_kws={'marker': markers})\n",
    "g = g.map_diag(sns.kdeplot)\n",
    "# g = g.map_lower(sns.scatterplot, edgecolor='w', s=20, alpha=0.5)\n",
    "g = g.map_upper(sns.kdeplot, shade=True, shade_lowest=False)\n",
    "g = g.map_upper(sns.kdeplot, shade=True)\n",
    "# g = g.add_legend({i:l for i,l in enumerate(categories)})\n",
    "g.savefig('../artifacts/lgkm_kde_test.png', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D PCA\n",
    "\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA #Principal Component Analysis\n",
    "# import plotly as py\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "# from utils import TOTUtils, tohex\n",
    "# from clustering import LGKMeansUtils\n",
    "\n",
    "# n_outputs = 5\n",
    "# features = TOTUtils.get_feature_names()\n",
    "# colors = [tohex(r,g,b) for r,g,b in sns.color_palette('rainbow_r', n_outputs)]\n",
    "# lgkmc = LGKMeansUtils.load('../artifacts/lgkm.pkl')\n",
    "# regions = lgkmc.get_regions(sort=False)[0:1000]\n",
    "\n",
    "# X, y, rX = zip(*[(r.X[i], r.y[i], ri) for ri,r in enumerate(regions) for i in range(r.n)])\n",
    "# viz_df = pd.DataFrame(X, columns=features)\n",
    "# viz_df['y'] = y\n",
    "# viz_df['region'] = rX\n",
    "# plot_X = viz_df.drop(['y', 'region'], axis=1)\n",
    "# pcs_2d = pd.DataFrame(PCA(n_components=2).fit_transform(plot_X), columns=['pc1', 'pc2'])\n",
    "# plot_X = pd.concat([plot_X, pcs_2d], axis=1, join='inner')\n",
    "# data = []\n",
    "# for i,r in enumerate(regions):\n",
    "#     r_X = plot_X[viz_df['region'] == i]\n",
    "#     trace = go.Scatter(x=r_X['pc1'], y=r_X['pc2'], mode='markers', name=f'region_{i}', marker=dict(color=colors[r.category]), text=None)\n",
    "#     data.append(trace)\n",
    "# layout = dict(title='Regions in 2D using PCA',\n",
    "#               xaxis=dict(title='PC1', ticklen=5, zeroline=False),\n",
    "#               yaxis=dict(title='PC2', ticklen=5, zeroline=False))\n",
    "# fig = dict(data=data, layout=layout)\n",
    "# iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3D PCA\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA #Principal Component Analysis\n",
    "# import plotly as py\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "# from utils import TOTUtils, tohex\n",
    "# from clustering import LGKMeansUtils\n",
    "\n",
    "# n_outputs = 5\n",
    "# features = TOTUtils.get_feature_names()\n",
    "# lgkmc = LGKMeansUtils.load('../artifacts/lgkm.pkl')\n",
    "# regions = lgkmc.get_regions(sort=False)[0:100]\n",
    "# colors = [tohex(r,g,b) for r,g,b in sns.color_palette('rainbow_r', n_outputs)]\n",
    "\n",
    "# X, y, rX = zip(*[(r.X[i], r.y[i], ri) for ri,r in enumerate(regions) for i in range(r.n)])\n",
    "# viz_df = pd.DataFrame(X, columns=features)\n",
    "# viz_df['y'] = y\n",
    "# viz_df['region'] = rX\n",
    "# plot_X = viz_df.drop(['y', 'region'], axis=1)\n",
    "# pcs_3d = pd.DataFrame(PCA(n_components=3).fit_transform(plot_X), columns=['pc1', 'pc2', 'pc3'])\n",
    "# plot_X = pd.concat([plot_X, pcs_3d], axis=1, join='inner')\n",
    "# data = []\n",
    "# for i,r in enumerate(regions):\n",
    "#     r_X = plot_X[viz_df['region'] == i]\n",
    "#     trace = go.Scatter3d(x=r_X['pc1'], y=r_X['pc2'], z=r_X['pc3'], mode='markers', name=f'region_{i}', marker=dict(color=colors[r.category]), text=None)\n",
    "#     data.append(trace)\n",
    "# layout = dict(title='Regions in 2D using PCA',\n",
    "#               xaxis=dict(title='PC1', ticklen=5, zeroline=False),\n",
    "#               yaxis=dict(title='PC2', ticklen=5, zeroline=False))\n",
    "# fig = dict(data=data, layout=layout)\n",
    "# iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = TOTUtils.get_feature_names()\n",
    "lgkmc = LGKMeansUtils.load('../artifacts/lgkm.pkl')\n",
    "regions = lgkmc.get_regions(sort=True)\n",
    "np.unique([r.category for r in regions[:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-SNE\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from utils import TOTUtils, tohex\n",
    "from clustering import LGKMeansUtils\n",
    "from IPython.display import display\n",
    "\n",
    "features = TOTUtils.get_feature_names()\n",
    "lgkmc = LGKMeansUtils.load('../artifacts/lgkm.pkl')\n",
    "regions = lgkmc.get_regions(sort=True)\n",
    "regions = regions[:20]\n",
    "\n",
    "X, y, rX = zip(*[(r.X[i], r.y[i], ri) for ri,r in enumerate(regions) for i in range(r.n)])\n",
    "cX, cy, crX = zip(*[(r.centroid, r.category, ri) for ri,r in enumerate(regions)])\n",
    "n_outputs = np.unique(y).shape[0]\n",
    "colors = [tohex(r,g,b) for r,g,b in sns.color_palette('rainbow_r', n_outputs)]\n",
    "df = pd.DataFrame(X, columns=features)\n",
    "df['y'] = y\n",
    "df['region'] = rX\n",
    "df['centroid'] = 0\n",
    "# df['radius'] = radii\n",
    "c_df = pd.DataFrame(cX, columns=features)\n",
    "c_df['y'] = cy\n",
    "c_df['region'] = crX\n",
    "c_df['centroid'] = 1\n",
    "# c_df['radius'] = cradii\n",
    "viz_df = pd.concat([df, c_df], ignore_index=True)\n",
    "plot_X = viz_df.drop(['y', 'region', 'centroid'], axis=1)\n",
    "plot_Meta = viz_df[['region', 'y', 'centroid']]\n",
    "\n",
    "perplexity = 100\n",
    "dimensions = 3\n",
    "outline_regions = True\n",
    "\n",
    "display(f'Performing TSNE on {len(regions)} regions...')\n",
    "tcs = [f'tc{i+1}' for i in range(dimensions)]\n",
    "tsne = pd.DataFrame(TSNE(n_components=dimensions, perplexity=perplexity).fit_transform(plot_X), columns=tcs)\n",
    "if dimensions == 1:\n",
    "    tsne['tc2'] = 0\n",
    "plot_X = pd.concat([plot_X, tsne], axis=1, join='inner')\n",
    "traces, shapes = [], []\n",
    "\n",
    "display(f'Plotting {len(regions)} regions as {dimensions}D TSNE...')\n",
    "for i,r in enumerate(regions):\n",
    "    r_X = plot_X[(plot_Meta['region'] == i) & (plot_Meta['centroid'] == 0)]\n",
    "    c_X = plot_X[(plot_Meta['region'] == i) & (plot_Meta['centroid'] == 1)]\n",
    "    rname, cname = f'r_{i}', f'c_{i}'\n",
    "    color = colors[r.category]\n",
    "    marker = dict(color=color, size=2)\n",
    "    cmarker = dict(marker, line=dict(color='#444444', width=1))\n",
    "    circle = dict(type='circle', xref='x', yref='y', fillcolor=color, line_color=color, opacity=0.11)\n",
    "    if dimensions < 3:\n",
    "        tc1, tc2 = tcs[0], tcs[1]\n",
    "        x, y, cx, cy = r_X[tc1], r_X[tc2], c_X[tc1], c_X[tc2]\n",
    "        x0, y0, x1, y1 = x.min(), y.min(), x.max(), y.max()\n",
    "        traces.append(go.Scatter(x=x, y=y, mode='markers', name=rname, marker=marker))\n",
    "        traces.append(go.Scatter(x=cx, y=cy, mode='markers', name=cname, marker=cmarker, showlegend=False))\n",
    "        if outline_regions:\n",
    "            shapes.append(dict(circle, x0=x0, y0=y0, x1=x1, y1=y1))\n",
    "    else:\n",
    "        tc1, tc2, tc3 = tcs[0], tcs[1], tcs[2]\n",
    "        x, y, z, cx, cy, cz = r_X[tc1], r_X[tc2], r_X[tc3], c_X[tc1], c_X[tc2], c_X[tc3]\n",
    "        traces.append(go.Scatter3d(x=x, y=y, z=z, mode='markers', name=rname, marker=marker))\n",
    "        traces.append(go.Scatter3d(x=cx, y=cy, z=cz, mode='markers', marker=cmarker, showlegend=False))\n",
    "        if outline_regions:\n",
    "            traces.append(go.Mesh3d(alphahull=5, opacity=.1, x=x, y=y, z=z, color=color, showscale=False, showlegend=False))\n",
    "\n",
    "title = f'Regions in {dimensions}D using T-SNE (p={perplexity})'\n",
    "axis, xtitle, ytitle = dict(title='', ticklen=5, zeroline=False), 'TC1', ('TC2' if dimensions > 1 else '')\n",
    "layout = dict(title=title, xaxis=dict(axis, title=xtitle), yaxis=dict(axis, title=ytitle), showlegend=True)\n",
    "\n",
    "fig = go.Figure(layout=layout)\n",
    "for t in traces:\n",
    "    fig.add_trace(t)\n",
    "if len(shapes) > 0:\n",
    "    fig.update_layout(shapes=shapes)\n",
    "\n",
    "fig.update_layout(showlegend=False)\n",
    "# fig.show()\n",
    "\n",
    "outdir = '../artifacts/plots'\n",
    "outpath = os.path.join(outdir, 'post-tsne-test.html')\n",
    "if not os.path.exists(outdir): os.makedirs(outdir)\n",
    "fig.write_html(outpath)\n",
    "display(f'wrote plot to {outpath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique([r.category for r in regions])\n",
    "regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapes\n",
    "viz_df['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGKMeansUtils.plot_regions(lgkmc, save=True, outdir='../artifacts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import unique\n",
    "# from numpy import where\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.cluster import OPTICS\n",
    "# from matplotlib import pyplot\n",
    "# # define the model\n",
    "# model = OPTICS(eps=0.8, min_samples=10)\n",
    "# # fit model and predict clusters\n",
    "# yhat = model.fit_predict(X)\n",
    "# # retrieve unique clusters\n",
    "# clusters = unique(yhat)\n",
    "# # create scatter plot for samples from each cluster\n",
    "# for cluster in clusters:\n",
    "# \t# get row indexes for samples with this cluster\n",
    "# \trow_ix = where(yhat == cluster)\n",
    "# \t# create scatter of these samples\n",
    "# \tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "# # show the plot\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from clustering import LGKMeansUtils\n",
    "X_orig, y_orig = LGKMeansUtils.load_dataset('../data/latest/verification.csv', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def sample(X, y, frac=1):\n",
    "    idxs = random.sample(range(X.shape[0]), int(X.shape[0] * frac))\n",
    "    return X[idxs], y[idxs]\n",
    "\n",
    "X, y = X_orig.copy(), y_orig.copy()\n",
    "X, y = sample(X, y, frac=0.02)\n",
    "\n",
    "dbscan = DBSCAN(eps=2.35, min_samples=2).fit(X)\n",
    "print(f'n_inputs:{X.shape[0]}, n_clusters:{np.unique(dbscan.labels_).shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.cluster import MeanShift, AffinityPropagation, SpectralClustering, estimate_bandwidth\n",
    "from sklearn.decomposition import PCA\n",
    "from clustering import LGKMeansUtils\n",
    "\n",
    "def sample(X, y, frac=1):\n",
    "    idxs = random.sample(range(X.shape[0]), int(X.shape[0] * frac))\n",
    "    return X[idxs], y[idxs]\n",
    "\n",
    "X, y = X_orig.copy(), y_orig.copy()\n",
    "X, y = sample(X, y, frac=0.001)\n",
    "# X = PCA(n_components=2).fit_transform(X)\n",
    "\n",
    "# bandwidth = estimate_bandwidth(X)\n",
    "# ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "# ms.fit(X)\n",
    "# labels = ms.labels_\n",
    "# cluster_centers = ms.cluster_centers_\n",
    "\n",
    "# af = AffinityPropagation(preference=-50).fit(X)\n",
    "# cluster_centers_indices = af.cluster_centers_indices_\n",
    "# labels = af.labels_\n",
    "\n",
    "sc = SpectralClustering(n_clusters=110)\n",
    "sc.fit(X)\n",
    "labels = sc.labels_\n",
    "\n",
    "labels_unique, label_counts = np.unique(labels, return_counts=True)\n",
    "n_clusters = labels_unique.shape[0]\n",
    "\n",
    "correct = [np.unique([y[i] for i in c]).shape[0] == 1 for c in [[i for i,l in enumerate(labels) if l==c] for c in range(n_clusters)]]\n",
    "print(f'number of clusters: {n_clusters} ({X.shape[0]} inputs)')\n",
    "print(f'num correct: {len([i for i in correct if i])}')\n",
    "print(f'num incorrect: {len([i for i in correct if not i])}')\n",
    "print(f'cluster sizes: {label_counts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from clustering import LGKMeansUtils\n",
    "\n",
    "# X, y = X_orig.copy(), LGKMeansUtils.reduce_classes(y_orig.copy())\n",
    "X, y = X_orig.copy(), y_orig.copy()\n",
    "randidxs = random.sample(range(X.shape[0]), 10000)\n",
    "X, y = X[randidxs], y[randidxs]\n",
    "n_inputs, n_categories = X.shape[0], np.unique(y, axis=0).shape[0]\n",
    "# X, y = PCA(n_components=2).fit_transform(X, y), np.array([tocat(yi, n_categories) for yi in y])\n",
    "n_features, n_targets = X.shape[1], y.shape[1]\n",
    "\n",
    "regions, remaining = [], [(X, y)]\n",
    "while remaining:\n",
    "    X, y = remaining.pop(0)\n",
    "    n = np.unique(y, axis=0).shape[0]\n",
    "    model = MeanShift(n_clusters=n)\n",
    "    clusters = model.fit_predict(np.concatenate([X, y], axis=1), categorical=list(range(n_features, n_features+n_targets)))\n",
    "    for c in np.unique(clusters):\n",
    "        # TODO: update region to support centroid's y value\n",
    "        centroid = model.cluster_centroids_[0][c]\n",
    "        xis = np.where(clusters == c)[0]\n",
    "        Xc, yc = X[xis], y[xis]\n",
    "        if np.unique(yc, axis=0).shape[0] == 1:\n",
    "            # TODO: update region class to support onehot\n",
    "            regions.append(LGKMeansRegion(centroid, Xc, np.array([np.where(yi==1)[0][0] for yi in yc])))\n",
    "        else:\n",
    "            remaining.append((Xc, yc))\n",
    "\n",
    "print(f'identified {len(regions)} regions from {n_inputs} inputs of {n_categories} categories')\n",
    "savepath = os.path.join('../artifacts', 'lgkp-regions.pkl')\n",
    "pickle.dump(regions, open(savepath, 'wb'))\n",
    "print(f'saved regions to {savepath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_ids, cluster_counts = np.unique(dbscan.labels_, return_counts=True)\n",
    "n_clusters = cluster_ids.shape[0]\n",
    "clusters = [[i for i,l in enumerate(dbscan.labels_) if l==c] for c in range(n_clusters)]\n",
    "correct = [np.unique([y[i] for i in c]).shape[0] == 1 for c in clusters]\n",
    "print(f'num correct: {len([i for i in correct if i])}')\n",
    "print(f'num incorrect: {len([i for i in correct if not i])}')\n",
    "print(f'cluster counts: {cluster_counts}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitvenvvenv2f570c7c66434947b458a57674f581a2",
   "display_name": "Python 3.7.7 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}